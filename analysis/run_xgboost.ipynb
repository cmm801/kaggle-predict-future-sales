{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.sparse.csr\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import importlib\n",
    "import kaggle_forecast \n",
    "importlib.reload( kaggle_forecast )\n",
    "\n",
    "from kaggle_forecast import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg = KaggleData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = { 'lag' : [1, 2, 3, 12], 'mean' : [2, 3, 6], 'shop_id' : [], 'item_id' : [], 'shop_item_id' : [], \\\n",
    "             'cat_id' : [], 'date_block_num' : [], 'month' : [], 'year' : [] }\n",
    "\n",
    "X, Y = get_labels_and_features( kg, features=features )\n",
    "\n",
    "# Get the combined features in matrix form for the train, validation and test sets\n",
    "xx_raw, yy_raw = combine_features( X, Y )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pandas Data Frames from the numpy matrices\n",
    "df_dict = dict()\n",
    "labels = xx_raw[DESC]\n",
    "for ds in [ TRAIN, VALID, TEST ]:\n",
    "    df_dict[ds] = pd.DataFrame( np.hstack( [ xx_raw[ds], yy_raw[ds] ] ), columns = xx_raw[DESC] + [TARGET_COL] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the data after a certain observation month\n",
    "date_block_cutoff = 10\n",
    "for ds in [ TRAIN, VALID, TEST ]:\n",
    "    df_dict[ds] = get_recent_data( df_dict[ds], date_block_cutoff=date_block_cutoff )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip the historical sales into the interval [0,20]\n",
    "lower_limit = 0\n",
    "upper_limit = 20\n",
    "for ds in [ TRAIN, VALID ]:\n",
    "    df_dict[ds][TARGET_COL] = np.maximum( lower_limit, df_dict[ds][TARGET_COL] )\n",
    "    df_dict[ds][TARGET_COL] = np.minimum( upper_limit, df_dict[ds][TARGET_COL] )    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-27 15:11:54.612267 : sales_mean_item_id\n",
      "2019-06-27 15:12:29.191426 : sales_mean_shop_id\n",
      "2019-06-27 15:12:56.848402 : sales_mean_cat_id\n",
      "2019-06-27 15:13:23.691993 : sales_mean_shop_item_id\n",
      "2019-06-27 15:15:45.395135 : sales_mean_date_block_num\n",
      "2019-06-27 15:16:15.460565 : sales_mean_month\n",
      "2019-06-27 15:16:46.645818 : sales_mean_06_mean_item_id\n",
      "2019-06-27 15:17:24.166455 : sales_mean_06_mean_shop_id\n",
      "2019-06-27 15:17:56.965197 : sales_mean_06_mean_cat_id\n",
      "2019-06-27 15:18:30.102644 : sales_mean_06_mean_shop_item_id\n",
      "2019-06-27 15:20:58.841546 : sales_mean_06_mean_date_block_num\n",
      "2019-06-27 15:21:34.597509 : sales_mean_06_mean_month\n"
     ]
    }
   ],
   "source": [
    "alpha = 5\n",
    "n_splits = 5\n",
    "target_cols = [ 'sales', 'sales_mean_06' ]\n",
    "group_cols = [ 'item_id', 'shop_id', 'cat_id', 'shop_item_id', 'date_block_num', 'month' ]\n",
    "\n",
    "for target_col in target_cols:\n",
    "    for group_col in group_cols:\n",
    "\n",
    "        new_col_name = target_col + '_mean_' + group_col\n",
    "        print('{}'.format(datetime.datetime.now()) + ' : ' + new_col_name )\n",
    "\n",
    "        if new_col_name not in df_dict[TRAIN]:\n",
    "            df_dict[TRAIN][new_col_name] = encode_means_with_cv( df_dict[TRAIN], \\\n",
    "                                        target_col=target_col, group_col=group_col, n_splits=n_splits ).to_numpy()\n",
    "\n",
    "        if new_col_name not in df_dict[VALID]:\n",
    "            df_dict[VALID][new_col_name] = encode_means_from_test_train_split( df_dict[TRAIN], df_dict[VALID], \\\n",
    "                                        target_col=target_col, group_col=group_col)    \n",
    "\n",
    "        if new_col_name not in df_dict[TEST]:\n",
    "            test_data = pd.concat( [ df_dict[TRAIN], df_dict[VALID] ])                \n",
    "            df_dict[TEST][new_col_name] = encode_means_from_test_train_split( test_data, df_dict[VALID], \\\n",
    "                                        target_col=target_col, group_col=group_col)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-27 15:22:10.898715 : 50\n",
      "valid RMSE 0.7439604919385264\n",
      "2019-06-27 15:33:45.926359\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 50\n",
    "max_depth = 4           # No lower than 3. Increase until performance stops improving\n",
    "learning_rate = 0.05    # Keep in the range of 0.01 and 0.1\n",
    "gamma = 5               # Regularization parameter: use value 0, 1, or 5\n",
    "colsample_bytree = 0.2  # Between 0.3 and 0.8 when dataset has many columns\n",
    "\n",
    "print('{} : {}'.format(datetime.datetime.now(), n_estimators  ) )\n",
    "# Construct the model\n",
    "model_constructor_fun = lambda : XGBRegressor( n_estimators=n_estimators, \\\n",
    "                                               gamma=gamma, \\\n",
    "                                               colsample_bytree=colsample_bytree,\\\n",
    "                                               max_depth=max_depth, \\\n",
    "                                               learning_rate=learning_rate )\n",
    "\n",
    "model_train = fit_model( model_constructor_fun, TRAIN, df_dict )\n",
    "\n",
    "# Check the out-of-sample fit for the validation set\n",
    "yhat_valid = predict_model( model_train, VALID, df_dict, clip_forecasts=(0,20) )\n",
    "\n",
    "print('{}'.format(datetime.datetime.now()  ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE nan\n"
     ]
    }
   ],
   "source": [
    "model_test = fit_model( model_constructor_fun, TEST, df_dict )\n",
    "\n",
    "# Check the out-of-sample fit for the test set\n",
    "yhat_test = predict_model( model_test, TEST, df_dict, clip_forecasts=(0,20) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = '../forecasts/xgboost_03.csv'\n",
    "write_forecast_to_csv( kg, yhat_test, output_file )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (python37)",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
