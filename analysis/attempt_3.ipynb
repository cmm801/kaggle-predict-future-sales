{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7710689317245613"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = np.log(0.3)\n",
    "beta = np.log(0.7)\n",
    "\n",
    "(1.01 + beta ) / (beta - alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all csv file data\n",
    "\n",
    "sales = pd.read_csv( '../input/sales_train.csv')\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "item_cat = pd.read_csv( '../input/item_categories.csv')\n",
    "item = pd.read_csv( '../input/items.csv')\n",
    "sub = pd.read_csv( '../input/sample_submission.csv')\n",
    "shops = pd.read_csv( '../input/shops.csv')\n",
    "test = pd.read_csv( '../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat the date column\n",
    "sales.date = sales.date.apply( lambda x: datetime.datetime.strptime( x, '%d.%m.%Y' ) )\n",
    "\n",
    "# Add month and year columns\n",
    "sales['month'] = [ x.month for x in sales.date ]\n",
    "sales['year'] = [ x.year for x in sales.date ]\n",
    "sales['year_month'] = sales.year * 100 + sales.month\n",
    "\n",
    "# Add the item_category_id to the training set\n",
    "sales = sales.set_index('item_id').join(item.set_index('item_id')).drop('item_name', axis=1).reset_index()\n",
    "test = test.set_index('item_id').join(item.set_index('item_id')).drop('item_name', axis=1).reset_index()\n",
    "\n",
    "# Add a unique id for the shop + item combo\n",
    "sales['shop_item_id'] = sales.shop_id + sales.item_id * 100\n",
    "test['shop_item_id'] = test.shop_id + test.item_id * 100\n",
    "sales['shop_cat_id'] = sales.shop_id + sales.item_category_id * 100\n",
    "test['shop_cat_id'] = test.shop_id + test.item_category_id * 100\n",
    "\n",
    "# Add the revenue\n",
    "sales[ \"revenue\" ] = sales.item_price * sales.item_cnt_day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_rules = {'item_price' : \"mean\", \"revenue\" : \"sum\", \"item_cnt_day\" : \"sum\" }\n",
    "monthly_shop_item = sales.groupby([ \"year_month\", 'date_block_num', \"shop_item_id\", \"item_id\", \"shop_id\", \"item_category_id\" ] ).agg( agg_rules ).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_pivot_ts( input_table, pivot_column, val_column, agg_rule, missing_method ):\n",
    "    \n",
    "        # Make time series out of the monthly  sales\n",
    "        tmp_table = input_table.groupby( [ 'year_month', pivot_column ] ).agg( { val_column : agg_rule } ).reset_index()\n",
    "        ts = tmp_table.pivot_table( val_column, index=\"year_month\", columns=pivot_column )\n",
    "        \n",
    "        # Fill missing values with 0\n",
    "        if missing_method == \"zero\":\n",
    "            ts = ts.fillna(0)\n",
    "        elif missing_method == 'ffill':\n",
    "            ts = ts.fillna(method=missing_method)\n",
    "        else:\n",
    "            ValueError( 'Unsupported value: .' + missing_method )\n",
    "        \n",
    "        # Set negative values to 0\n",
    "        ts[ ts < 0 ] = 0\n",
    "        \n",
    "        # Set the index to be the dates\n",
    "        dates = year_month_to_datetime(ts.index.values )\n",
    "        ts = ts.set_index( pd.Index( dates ) )\n",
    "    \n",
    "        # Make sure the dates are sorted\n",
    "        ts.sort_index(axis=0, ascending=True, inplace=True )\n",
    "        \n",
    "        return(ts)\n",
    "    \n",
    "\n",
    "# Define a helper function\n",
    "def year_month_to_datetime( ym ):\n",
    "\n",
    "    if isinstance(ym, float ) or isinstance(ym, int):\n",
    "        m = ym % 100\n",
    "        y = ym // 100\n",
    "\n",
    "        output = datetime.date( y, m, 1 )\n",
    "    else:\n",
    "        if isinstance( ym, pd.Series):\n",
    "            ym = list(ym)\n",
    "\n",
    "        output = []\n",
    "        for j in range(len(ym)):\n",
    "            m = ym[j] % 100\n",
    "            y = ym[j] // 100\n",
    "\n",
    "            output.append( datetime.date( y, m, 1 ) )\n",
    "\n",
    "    return output    \n",
    "\n",
    "def rmse( x1, x2 ):\n",
    "    \n",
    "    res = np.sqrt( np.mean( (x1.ravel()-x2.ravel()) ** 2 ) )\n",
    "    return(res)    \n",
    "\n",
    "\n",
    "def decompose_shop_item_id( shop_item_id ):\n",
    "    \n",
    "    item_id = shop_item_id // 100\n",
    "    shop_id = shop_item_id % 100\n",
    "\n",
    "    return shop_id, item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series of the variables that we will use for prediction\n",
    "ts_item_day = create_pivot_ts( monthly_shop_item, \"shop_item_id\", \"item_cnt_day\", \"sum\", 'zero'  )\n",
    "ts_item_prc = create_pivot_ts( monthly_shop_item, \"shop_item_id\", \"item_price\", \"sum\", \"ffill\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series of the shop id and category id for the different shop/item combinations\n",
    "\n",
    "shop_id, item_id = decompose_shop_item_id( ts_item_day.columns )\n",
    "\n",
    "ts_shop_id = pd.DataFrame( np.vstack( [ shop_id.values ] * ts_item_day.shape[0] ), index=ts_item_day.index )\n",
    "ts_shop_id.columns = ts_item_day.columns\n",
    "\n",
    "uniq_items = item_id.unique()\n",
    "cat_ids_for_uniq_ids = [ item[ item.item_id == x ].item_category_id.iloc[0] for x in uniq_items ]\n",
    "id_map = dict(zip( list(uniq_items), cat_ids_for_uniq_ids ))\n",
    "cat_ids = pd.Series( [ id_map[x] for x in item_id ] )\n",
    "\n",
    "ts_cat_id = pd.DataFrame( np.vstack( [ cat_ids.values ] * ts_item_day.shape[0] ), index=ts_item_day.index )\n",
    "ts_cat_id.columns = ts_item_day.columns\n",
    "\n",
    "date_block_nums = np.array(list(range(0,ts_shop_id.shape[0])))[:,np.newaxis]\n",
    "ts_date_num_block = pd.DataFrame( np.hstack( [ date_block_nums ] * ts_item_day.shape[1] ), index=ts_item_day.index )\n",
    "ts_date_num_block.columns = ts_item_day.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "VALIDATION_PROPORTION = 0.1\n",
    "\n",
    "def get_regression_vectors_from_matrix( input_mtx, is_X, seed=SEED, valid_prop=VALIDATION_PROPORTION ):\n",
    "\n",
    "    N = input_mtx.shape[1]\n",
    "    new_row = np.array( [np.NaN] * N ).reshape(1,N)    \n",
    "    if is_X:\n",
    "        M = np.vstack( [ new_row, input_mtx.to_numpy() ] )\n",
    "    else:\n",
    "        M = np.vstack( [ input_mtx.to_numpy(), new_row ] )\n",
    "\n",
    "    # Randomly split the validation and training sets\n",
    "    s_train_valid = M[:-1].ravel()[:,np.newaxis]\n",
    "    s_train, s_valid = split_train_validation_sets( s_train_valid, seed=seed, valid_prop=valid_prop )\n",
    "    \n",
    "    # Get the test set\n",
    "    s_test = M[-1].ravel()[:,np.newaxis]\n",
    "\n",
    "    return s_train, s_valid, s_test\n",
    "\n",
    "\n",
    "def split_train_validation_sets( s, seed=SEED, valid_prop=VALIDATION_PROPORTION ):\n",
    "    \n",
    "    rng = np.random.RandomState(42)\n",
    "    N = len(s)\n",
    "    n_valid = int( np.floor( N * valid_prop ))\n",
    "    \n",
    "    idx = rng.choice(N, N, replace=False)\n",
    "    s_valid = s[ idx[:n_valid] ]\n",
    "    s_train = s[ idx[n_valid:] ]\n",
    "    \n",
    "    return s_train, s_valid\n",
    "    \n",
    "\n",
    "def remove_nan_rows( xx_input, yy_input ):\n",
    "    idx = np.any( np.isnan( xx_input ), axis=1 ).ravel() | np.any( np.isnan( yy_input ), axis=1 ).ravel() \n",
    "    xx_output = xx_input[~idx,:]\n",
    "    yy_output = yy_input[~idx,:]    \n",
    "    return xx_output, yy_output\n",
    "    \n",
    "    \n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:,:] - cumsum[:-N,:]) / float(N)\n",
    "\n",
    "def format_forecast( test_ids, fcst ):\n",
    "    \n",
    "    output = pd.Series( np.zeros_like(test_ids), index=test_ids, name=\"item_cnt_month\" )\n",
    "\n",
    "    # Only keep the forecast values that are in the test set\n",
    "    fcst_sub = fcst[ [ x in test_ids for x in fcst.index.values ] ]\n",
    "    \n",
    "    # Copy the forecasts into the same order as the test IDs\n",
    "    output[ fcst_sub.index.values ] = fcst_sub.values\n",
    "    \n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the test and train sets from the observation matrices\n",
    "yy_train, yy_valid, yy_test = get_regression_vectors_from_matrix( ts_item_day, is_X=False )\n",
    "\n",
    "# Get feature vectors\n",
    "X_train = []\n",
    "X_test = []\n",
    "X_valid = []\n",
    "X_descrip = []\n",
    "\n",
    "# Use different sales lags as features\n",
    "c = 0\n",
    "lags = [1, 2, 3, 6, 12 ]\n",
    "for L in lags:\n",
    "    X_train.append([]), X_valid.append([]), X_test.append([])\n",
    "    x_lag_mtx = ts_item_day.shift(periods=L-1)\n",
    "    X_train[c], X_valid[c], X_test[c] = get_regression_vectors_from_matrix( x_lag_mtx, is_X=True)\n",
    "    X_descrip.append(  'sales_lag_{:02}'.format(L) )\n",
    "    c += 1\n",
    "\n",
    "# Use different means as features\n",
    "means = [2, 3, 6, 12]\n",
    "for M in means:\n",
    "    X_train.append([]), X_valid.append([]), X_test.append([])\n",
    "    x_mean_mtx = ts_item_day.rolling(window=M).mean()    \n",
    "    X_train[c], X_valid[c], X_test[c] = get_regression_vectors_from_matrix(x_mean_mtx, is_X=True )\n",
    "    X_descrip.append( 'sales_mean_{:02}'.format(M) ) \n",
    "    c += 1\n",
    "    \n",
    "# Use different price lags as features\n",
    "lags = [1]\n",
    "for L in lags:\n",
    "    X_train.append([]), X_valid.append([]), X_test.append([])\n",
    "    x_lag_mtx = ts_item_prc.shift(periods=L-1)\n",
    "    X_train[c], X_valid[c], X_test[c] = get_regression_vectors_from_matrix( x_lag_mtx, is_X=True)\n",
    "    X_descrip.append( 'price_lag_{:02}'.format(L) )\n",
    "    c += 1\n",
    "    \n",
    "    \n",
    "# Add the shop id as a feature\n",
    "X_train.append([]), X_valid.append([]), X_test.append([])  \n",
    "X_train[c], X_valid[c], X_test[c] = get_regression_vectors_from_matrix( ts_shop_id, is_X=True )\n",
    "X_descrip.append( 'shop_id' )\n",
    "c += 1\n",
    "\n",
    "# Add the category id as a feature\n",
    "X_train.append([]), X_valid.append([]), X_test.append([])  \n",
    "X_train[c], X_valid[c], X_test[c] = get_regression_vectors_from_matrix( ts_cat_id, is_X=True )\n",
    "X_descrip.append( 'cat_id' )\n",
    "c += 1\n",
    "\n",
    "# Add the date block number as a feature\n",
    "X_train.append([]), X_valid.append([]), X_test.append([])  \n",
    "X_train[c], X_valid[c], X_test[c] = get_regression_vectors_from_matrix( ts_date_num_block, is_X=True )\n",
    "X_descrip.append( 'date_block_num' )\n",
    "c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all of the X vectors into a single feature matrix\n",
    "xx_train = np.hstack(X_train)\n",
    "xx_valid = np.hstack(X_valid)\n",
    "xx_test = np.hstack(X_test)\n",
    "\n",
    "# Remove all rows with NaNs in the Train and Validation sets\n",
    "# In the test set, all Y values are unknown, so we leave these alone\n",
    "xx_train, yy_train = remove_nan_rows( xx_train, yy_train )\n",
    "xx_valid, yy_valid = remove_nan_rows( xx_valid, yy_valid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_one_hot_encoding( descrip, train, valid, test, feature_name, binarizer ):\n",
    "\n",
    "    # Get the column with the target feature\n",
    "    idx = descrip.index(feature_name)\n",
    "    \n",
    "    # Update the descriptions of the features\n",
    "    new_cols = [ feature_name + \"_{:02d}\".format(x) for x in binarizer.classes_ ]    \n",
    "    new_descrip = descrip[:idx] + descrip[idx+1:] + new_cols\n",
    "    \n",
    "    # Update the training data\n",
    "    target_train = train[:,idx]\n",
    "    sub_train = np.hstack( [ train[:,:idx], train[:,idx+1:] ] )    \n",
    "    one_hot_train = binarizer.transform(target_train)\n",
    "    new_train = np.hstack( [ sub_train, one_hot_train ] )\n",
    "    \n",
    "    # Update the validation data\n",
    "    targe_valid = valid[:,idx]\n",
    "    sub_valid = np.hstack( [ valid[:,:idx], valid[:,idx+1:] ] )    \n",
    "    one_hot_valid = binarizer.transform(targe_valid)\n",
    "    new_valid = np.hstack( [ sub_valid, one_hot_valid ] )\n",
    "    \n",
    "    # Update the test data\n",
    "    target_test = test[:,idx]\n",
    "    sub_test = np.hstack( [ test[:,:idx], test[:,idx+1:] ] )    \n",
    "    one_hot_test = binarizer.transform(target_test)\n",
    "    new_test = np.hstack( [ sub_test, one_hot_test ] ) \n",
    "    \n",
    "    return new_descrip, new_train, new_valid, new_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace shop_id with one-hot encodings\n",
    "shop_binarizer = LabelBinarizer()\n",
    "shop_binarizer.fit(sales.shop_id.unique())\n",
    "X_descrip, xx_train, xx_valid, xx_test = add_one_hot_encoding( X_descrip, xx_train, xx_valid, xx_test, \"shop_id\", binarizer=shop_binarizer )\n",
    "\n",
    "# Replace category_id with one-hot encodings\n",
    "cat_binarizer = LabelBinarizer()\n",
    "cat_binarizer.fit(sales.item_category_id.unique())\n",
    "X_descrip, xx_train, xx_valid, xx_test =  add_one_hot_encoding( X_descrip, xx_train, xx_valid, xx_test, \"cat_id\", binarizer=cat_binarizer )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx_train_full = xx_train\n",
    "yy_train_full = yy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_full = xx_train_full.shape[0]\n",
    "N_train = N_full // 10\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "idx = rng.choice( N_full, N_full, replace=False )\n",
    "xx_train = xx_train_full[idx[0:N_train],:]\n",
    "yy_train = yy_train_full[idx[0:N_train],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE 1.7459644921217206\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "# Fit the model using the training data\n",
    "#model = LinearRegression()\n",
    "model = Ridge(alpha=0.6, normalize=True)\n",
    "model.fit(xx_train, yy_train)\n",
    "\n",
    "# Run the model on the validation set and see the score\n",
    "yhat_valid = model.predict(xx_valid).reshape(xx_valid.shape[0],1)\n",
    "yhat_valid = np.maximum(0, yhat_valid)\n",
    "\n",
    "# Check the goodness of fit\n",
    "res = rmse( yhat_valid, yy_valid)\n",
    "print( 'Validation RMSE {}'.format( res ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winsorize the non-categorical features\n",
    "\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "xx_train_w = xx_train.copy()\n",
    "xx_valid_w = xx_valid.copy()\n",
    "xx_test_w = xx_test.copy()\n",
    "\n",
    "p = 0.000001\n",
    "idx_last = X_descrip.index('price_lag_01')\n",
    "for j in range(0,idx_last+1):\n",
    "    xx_train_w[:,j] = winsorize( xx_train_w[:,j], (0, p) )\n",
    "    xx_valid_w[:,j] = winsorize( xx_valid_w[:,j], (0, p) )    \n",
    "    xx_test_w[:,j] = winsorize( xx_test_w[:,j], (0, p) )    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Fit the model using the training data\n",
    "model = SVR(C=1)\n",
    "model.fit(xx_train, yy_train)\n",
    "\n",
    "# Run the model on the validation set and see the score\n",
    "yhat_valid = model.predict(xx_valid).reshape(xx_valid.shape[0],1)\n",
    "yhat_valid = np.maximum(0, yhat_valid)\n",
    "\n",
    "# Check the goodness of fit\n",
    "res = rmse( yhat_valid, yy_valid)\n",
    "print( 'Validation RMSE {}'.format( res ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE 1.803924967460872\n"
     ]
    }
   ],
   "source": [
    "# Try to forecast using Random forests\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Fit the model using the training data\n",
    "model = RandomForestRegressor(n_estimators=10, max_depth=2)\n",
    "model.fit(xx_train, yy_train)\n",
    "\n",
    "# Run the model on the validation set and see the score\n",
    "yhat_valid = model.predict(xx_valid).reshape(xx_valid.shape[0],1)\n",
    "yhat_valid = np.maximum(0, yhat_valid)\n",
    "\n",
    "# Check the goodness of fit\n",
    "res = rmse( yhat_valid, yy_valid)\n",
    "print( 'Validation RMSE {}'.format( res ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE 1.965791369627067\n"
     ]
    }
   ],
   "source": [
    "# Try to forecast using Adaboost\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "sub_cols = [0,2,5,11,17]\n",
    "sub_cols = [0,2,5,11,17]\n",
    "xx_train_sub = xx_train[:,sub_cols]\n",
    "xx_valid_sub = xx_valid[:,sub_cols]\n",
    "xx_test_sub = xx_test[:,sub_cols]\n",
    "\n",
    "# Fit the model using the training data\n",
    "BE = DecisionTreeRegressor(max_depth=3)\n",
    "BE = LinearRegression()\n",
    "model = AdaBoostRegressor(n_estimators=50, random_state=0, base_estimator=BE, loss=\"linear\", learning_rate=0.0005 )\n",
    "model.fit(xx_train_sub, yy_train)\n",
    "\n",
    "# Run the model on the validation set and see the score\n",
    "yhat_valid = model.predict(xx_valid_sub).reshape(xx_valid_sub.shape[0],1)\n",
    "yhat_valid = np.maximum(0, yhat_valid)\n",
    "\n",
    "# Check the goodness of fit\n",
    "res = rmse( yhat_valid, yy_valid)\n",
    "print( 'Validation RMSE {}'.format( res ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE 1.7383397340041775\n"
     ]
    }
   ],
   "source": [
    "# Try to forecast using Random forests\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "# Fit the model using the training data\n",
    "model = Ridge(alpha=0.6, normalize=True)\n",
    "model.fit(xx_train, yy_train)\n",
    "\n",
    "# Run the model on the validation set and see the score\n",
    "yhat_valid = model.predict(xx_valid).reshape(xx_valid.shape[0],1)\n",
    "yhat_valid = np.maximum(0, yhat_valid)\n",
    "\n",
    "# Check the goodness of fit\n",
    "res = rmse( yhat_valid, yy_valid)\n",
    "print( 'Validation RMSE {}'.format( res ) )\n",
    "\n",
    "# Make a forecast using the test data\n",
    "yhat_test = model.predict(xx_test).reshape(xx_test.shape[0],1)\n",
    "yhat_test = np.maximum(0, yhat_test)\n",
    "\n",
    "# Format the forecast as a Pandas Series and write the output to .csv\n",
    "fcst = pd.Series( yhat_test.ravel(), index=pd.Index(ts_item_day.columns) )\n",
    "output = format_forecast( test.ID, fcst )\n",
    "\n",
    "output.to_csv( '../forecasts/forecast_10.csv', index=True, header=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_item_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>revenue</th>\n",
       "      <th>item_cnt_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201301</td>\n",
       "      <td>0</td>\n",
       "      <td>1925</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201301</td>\n",
       "      <td>0</td>\n",
       "      <td>2701</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201301</td>\n",
       "      <td>0</td>\n",
       "      <td>2702</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2499.0</td>\n",
       "      <td>2499.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201301</td>\n",
       "      <td>0</td>\n",
       "      <td>2710</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201301</td>\n",
       "      <td>0</td>\n",
       "      <td>2719</td>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>2499.0</td>\n",
       "      <td>2499.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_month  date_block_num  shop_item_id  item_id  shop_id  \\\n",
       "0      201301               0          1925       19       25   \n",
       "1      201301               0          2701       27        1   \n",
       "2      201301               0          2702       27        2   \n",
       "3      201301               0          2710       27       10   \n",
       "4      201301               0          2719       27       19   \n",
       "\n",
       "   item_category_id  item_price  revenue  item_cnt_day  \n",
       "0                40        28.0     28.0           1.0  \n",
       "1                19      1890.0   1890.0           1.0  \n",
       "2                19      2499.0   2499.0           1.0  \n",
       "3                19      1890.0   1890.0           1.0  \n",
       "4                19      2499.0   2499.0           1.0  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_shop_item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'price_lag_12'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (python37)",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
