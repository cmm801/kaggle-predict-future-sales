{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all csv file data\n",
    "\n",
    "sales = pd.read_csv( 'data/sales_train.csv')\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "item_cat = pd.read_csv( 'data/item_categories.csv')\n",
    "item = pd.read_csv( 'data/items.csv')\n",
    "sub = pd.read_csv( 'data/sample_submission.csv')\n",
    "shops = pd.read_csv( 'data/shops.csv')\n",
    "test = pd.read_csv( 'data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat the date column\n",
    "sales.date = sales.date.apply( lambda x: datetime.datetime.strptime( x, '%d.%m.%Y' ) )\n",
    "\n",
    "# Add month and year columns\n",
    "sales['month'] = [ x.month for x in sales.date ]\n",
    "sales['year'] = [ x.year for x in sales.date ]\n",
    "sales['year_month'] = sales.year * 100 + sales.month\n",
    "\n",
    "# Add the item_category_id to the training set\n",
    "sales = sales.set_index('item_id').join(item.set_index('item_id')).drop('item_name', axis=1).reset_index()\n",
    "test = test.set_index('item_id').join(item.set_index('item_id')).drop('item_name', axis=1).reset_index()\n",
    "\n",
    "# Add a unique id for the shop + item combo\n",
    "sales['shop_item_id'] = sales.shop_id + sales.item_id * 100\n",
    "test['shop_item_id'] = test.shop_id + test.item_id * 100\n",
    "sales['shop_cat_id'] = sales.shop_id + sales.item_category_id * 100\n",
    "test['shop_cat_id'] = test.shop_id + test.item_category_id * 100\n",
    "\n",
    "# Add the revenue\n",
    "sales[ \"revenue\" ] = sales.item_price * sales.item_cnt_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_rules = {'item_price' : \"mean\", \"revenue\" : \"sum\", \"item_cnt_day\" : \"sum\" }\n",
    "sales_monthly = sales.groupby([ \"year_month\", \"shop_id\", \"item_id\", \"item_category_id\", \"shop_item_id\", \"shop_cat_id\" ] ).agg( agg_rules ).reset_index()\n",
    "\n",
    "agg_rules = {'item_price' : \"mean\", \"revenue\" : \"sum\", \"item_cnt_day\" : \"sum\", \"shop_id\" : \"count\", \"item_id\" : \"count\" }\n",
    "sales_monthly_cat = sales_monthly.groupby([ \"year_month\", \"item_category_id\" ] ).agg( agg_rules ).reset_index()\n",
    "\n",
    "agg_rules = {'item_price' : \"mean\", \"revenue\" : \"sum\", \"item_cnt_day\" : \"sum\", \"item_category_id\" : \"count\", \"item_id\" : \"count\" }\n",
    "sales_monthly_shop = sales_monthly.groupby([ \"year_month\", \"shop_id\" ] ).agg( agg_rules ).reset_index()\n",
    "\n",
    "agg_rules = {'item_price' : \"mean\", \"revenue\" : \"sum\", \"item_cnt_day\" : \"sum\", \"shop_id\" : \"count\" }\n",
    "sales_monthly_item = sales_monthly.groupby([ \"year_month\", \"item_id\" ] ).agg( agg_rules ).reset_index()\n",
    "\n",
    "agg_rules = {'item_price' : \"mean\", \"revenue\" : \"sum\", \"item_cnt_day\" : \"sum\" }\n",
    "sales_monthly_shop_item = sales_monthly.groupby([ \"year_month\", \"shop_item_id\", \"item_id\", \"shop_id\", \"item_category_id\" ] ).agg( agg_rules ).reset_index()\n",
    "\n",
    "agg_rules = {'item_price' : \"mean\", \"revenue\" : \"sum\", \"item_cnt_day\" : \"sum\", \"item_id\" : \"sum\" }\n",
    "sales_monthly_shop_cat = sales_monthly.groupby([ \"year_month\", \"shop_cat_id\", \"item_category_id\", \"shop_id\" ] ).agg( agg_rules ).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_pivot_ts( input_table, pivot_column ):\n",
    "    \n",
    "        # Make time series out of the monthly  sales\n",
    "        tmp_table = input_table.groupby( [ 'year_month', pivot_column ] ).agg( { 'item_cnt_day' : 'sum' } ).reset_index()\n",
    "        ts = tmp_table.pivot_table( \"item_cnt_day\", index=\"year_month\", columns=pivot_column )\n",
    "        \n",
    "        # Fill missing values with 0\n",
    "        ts = ts.fillna(0)\n",
    "        \n",
    "        # Set negative values to 0\n",
    "        ts[ ts < 0 ] = 0\n",
    "        \n",
    "        # Set the index to be the dates\n",
    "        dates = year_month_to_datetime(ts.index.values )\n",
    "        ts = ts.set_index( pd.Index( dates ) )\n",
    "    \n",
    "        # Make sure the dates are sorted\n",
    "        ts.sort_index(axis=0, ascending=True, inplace=True )\n",
    "        \n",
    "        return(ts)\n",
    "        \n",
    "\n",
    "# Define a helper function\n",
    "def year_month_to_datetime( ym ):\n",
    "\n",
    "    if isinstance(ym, float ) or isinstance(ym, int):\n",
    "        m = ym % 100\n",
    "        y = ym // 100\n",
    "\n",
    "        output = datetime.date( y, m, 1 )\n",
    "    else:\n",
    "        if isinstance( ym, pd.Series):\n",
    "            ym = list(ym)\n",
    "\n",
    "        output = []\n",
    "        for j in range(len(ym)):\n",
    "            m = ym[j] % 100\n",
    "            y = ym[j] // 100\n",
    "\n",
    "            output.append( datetime.date( y, m, 1 ) )\n",
    "\n",
    "    return output    \n",
    "\n",
    "def rmse( x1, x2 ):\n",
    "    \n",
    "    res = np.sqrt( np.mean( (x1.ravel()-x2.ravel()) ** 2 ) )\n",
    "    return(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pivot table containing sales for all shop and item combinations\n",
    "sales_monthly_shop_item = create_pivot_ts( sales_monthly, 'shop_item_id' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the shop/item combinations that appear in the test set\n",
    "Z = sales_monthly_shop_item.loc[ :, [ x in test.shop_item_id for x in sales_monthly_shop_item ] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_forecast( test_ids, fcst ):\n",
    "    \n",
    "    output = pd.Series( np.zeros_like(test_ids), index=test_ids, name=\"item_cnt_month\" )\n",
    "\n",
    "    # Copy the forecasts into the same order as the test IDs\n",
    "    output[ fcst.index.values ] = fcst.values\n",
    "    \n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "VALIDATION_PROPORTION = 0.1\n",
    "\n",
    "def get_regression_vectors_from_matrix( input_mtx, is_X, seed=SEED, valid_prop=VALIDATION_PROPORTION ):\n",
    "\n",
    "    N = input_mtx.shape[1]\n",
    "    new_row = np.array( [np.NaN] * N ).reshape(1,N)    \n",
    "    if is_X:\n",
    "        M = np.vstack( [ new_row, input_mtx.to_numpy() ] )\n",
    "    else:\n",
    "        M = np.vstack( [ input_mtx.to_numpy(), new_row ] )\n",
    "\n",
    "    # Randomly split the validation and training sets\n",
    "    s_train_valid = M[:-1].ravel()[:,np.newaxis]\n",
    "    s_train, s_valid = split_train_validation_sets( s_train_valid, seed=seed, valid_prop=valid_prop )\n",
    "    \n",
    "    # Get the test set\n",
    "    s_test = M[-1].ravel()[:,np.newaxis]    \n",
    "\n",
    "    return s_train, s_valid, s_test\n",
    "\n",
    "\n",
    "def split_train_validation_sets( s, seed=SEED, valid_prop=VALIDATION_PROPORTION ):\n",
    "    \n",
    "    rng = np.random.RandomState(42)\n",
    "    N = len(s)\n",
    "    n_valid = int( np.floor( N * valid_prop ))\n",
    "    \n",
    "    idx = rng.choice(N, N, replace=False)\n",
    "    s_valid = s[ idx[:n_valid] ]\n",
    "    s_train = s[ idx[n_valid:] ]\n",
    "    \n",
    "    return s_train, s_valid\n",
    "    \n",
    "\n",
    "def remove_nan_rows( xx_input, yy_input ):\n",
    "    idx = np.any( np.isnan( xx_input ), axis=1 ).ravel() | np.any( np.isnan( yy_input ), axis=1 ).ravel() \n",
    "    xx_output = xx_input[~idx,:]\n",
    "    yy_output = yy_input[~idx,:]    \n",
    "    return xx_output, yy_output\n",
    "    \n",
    "    \n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:,:] - cumsum[:-N,:]) / float(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the shop/item combinations that appear in the test set\n",
    "W = sales_monthly_shop_item.loc[ :, [ x in test.shop_item_id for x in sales_monthly_shop_item ] ]\n",
    "dW = W - W.shift(periods=1)\n",
    "Z = W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the test and train sets from the observation matrices\n",
    "yy_train, yy_valid, yy_test = get_regression_vectors_from_matrix( Z, is_X=False )\n",
    "W_train, W_valid, W_test = get_regression_vectors_from_matrix( W, is_X=True)\n",
    "\n",
    "# Get feature vectors\n",
    "X_train = [None] * 23\n",
    "X_test = [None] * 23\n",
    "X_valid = [None] * 23\n",
    "\n",
    "# Use different lags as features\n",
    "c = 0\n",
    "for j in range(0, 12):\n",
    "    X_train[c], X_valid[c], X_test[c] = get_regression_vectors_from_matrix( Z.shift(periods=j), is_X=True)\n",
    "    c += 1\n",
    "    \n",
    "# Get rolling means\n",
    "for j in range(1, 12):\n",
    "    # Calculate the rolling mean\n",
    "    x_mean_mtx = Z.rolling(window=j+1).mean()\n",
    "    X_train[c], X_valid[c], X_test[c] = get_regression_vectors_from_matrix(x_mean_mtx, is_X=True )\n",
    "    c += 1\n",
    "\n",
    "# Combine all of the X vectors into a single feature matrix\n",
    "xx_train = np.hstack(X_train)\n",
    "xx_valid = np.hstack(X_valid)\n",
    "xx_test = np.hstack(X_test)\n",
    "\n",
    "# Remove all rows with NaNs in the Train and Validation sets\n",
    "# In the test set, all Y values are unknown, so we leave these alone\n",
    "W_train, _ = remove_nan_rows( W_train, np.hstack( [ xx_train, yy_train ] ) )\n",
    "W_valid, _ = remove_nan_rows( W_valid, np.hstack( [ xx_valid, yy_valid ] ) )\n",
    "\n",
    "xx_train, yy_train = remove_nan_rows( xx_train, yy_train )\n",
    "xx_valid, yy_valid = remove_nan_rows( xx_valid, yy_valid )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE 1.4687934117681465\n"
     ]
    }
   ],
   "source": [
    "# Predict with average of previous observation\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "# Run the model on the validation set and see the score\n",
    "yhat_valid = xx_valid[:,19].copy()\n",
    "\n",
    "# Set the forecast to 0 if the past few observations have been 0\n",
    "idx = xx_valid[:,0:1].sum(axis=1) == 0\n",
    "yhat_valid[idx] = 0\n",
    "yhat_valid = np.maximum(0, yhat_valid)\n",
    "\n",
    "# Check the goodness of fit\n",
    "res = rmse( yhat_valid, yy_valid)\n",
    "print( 'Validation RMSE {}'.format( res ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE 1.3694612664495778\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "# Fit the model using the training data\n",
    "model = LinearRegression()\n",
    "#model = Ridge(alpha=0.2, normalize=True)\n",
    "model.fit(xx_train, yy_train)\n",
    "\n",
    "# Run the model on the validation set and see the score\n",
    "yhat_valid = model.predict(xx_valid).reshape(xx_valid.shape[0],1)\n",
    "yhat_valid = np.maximum(0, yhat_valid)\n",
    "\n",
    "# Check the goodness of fit\n",
    "res = rmse( yhat_valid, yy_valid)\n",
    "print( 'Validation RMSE {}'.format( res ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 7.87 µs\n",
      "Validation RMSE 1.3903701542426856\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "# Try to forecast using Random forests\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Fit the model using the training data\n",
    "model = RandomForestRegressor(n_estimators=100, max_depth=2)\n",
    "model.fit(xx_train, yy_train)\n",
    "\n",
    "# Run the model on the validation set and see the score\n",
    "yhat_valid = model.predict(xx_valid).reshape(xx_valid.shape[0],1)\n",
    "yhat_valid = np.maximum(0, yhat_valid)\n",
    "\n",
    "# Check the goodness of fit\n",
    "res = rmse( yhat_valid, yy_valid)\n",
    "print( 'Validation RMSE {}'.format( res ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 8.34 µs\n",
      "Validation RMSE 1.369535774506645\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "# Try to forecast using Adaboost\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "sub_cols = [0,2,5,11,17]\n",
    "sub_cols = [0,2,5,11,17]\n",
    "xx_train_sub = xx_train[:,sub_cols]\n",
    "xx_valid_sub = xx_valid[:,sub_cols]\n",
    "xx_test_sub = xx_test[:,sub_cols]\n",
    "\n",
    "# Fit the model using the training data\n",
    "BE = DecisionTreeRegressor(max_depth=3)\n",
    "BE = LinearRegression()\n",
    "model = AdaBoostRegressor(n_estimators=80, random_state=0, base_estimator=BE, loss=\"linear\", learning_rate=0.001)\n",
    "model.fit(xx_train_sub, yy_train)\n",
    "\n",
    "# Run the model on the validation set and see the score\n",
    "yhat_valid = model.predict(xx_valid_sub).reshape(xx_valid_sub.shape[0],1)\n",
    "yhat_valid = np.maximum(0, yhat_valid)\n",
    "\n",
    "# Check the goodness of fit\n",
    "res = rmse( yhat_valid, yy_valid)\n",
    "print( 'Validation RMSE {}'.format( res ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 7.87 µs\n",
      "Validation RMSE 1.4045803663300878\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "# Try to forecast using Random forests\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "# Fit the model using the training data\n",
    "model = RandomForestRegressor(n_estimators=10, max_depth=2)\n",
    "model.fit(xx_train, yy_train)\n",
    "\n",
    "# Run the model on the validation set and see the score\n",
    "dyhat_valid = model.predict(xx_valid).reshape(xx_valid.shape[0],1)\n",
    "yhat_valid = W_valid + dyhat_valid\n",
    "yhat_valid = np.maximum(0, yhat_valid)\n",
    "\n",
    "# Check the goodness of fit\n",
    "res = rmse( yhat_valid, W_valid + yy_valid)\n",
    "print( 'Validation RMSE {}'.format( res ) )\n",
    "\n",
    "# Make a forecast using the test data\n",
    "dyhat_test = model.predict(xx_test).reshape(xx_test.shape[0],1)\n",
    "yhat_test = W_test + dyhat_test\n",
    "yhat_test = np.maximum(0, yhat_test)\n",
    "\n",
    "# Format the forecast as a Pandas Series and write the output to .csv\n",
    "fcst = pd.Series( yhat_test.ravel(), index=pd.Index(Z.columns) )\n",
    "output = format_forecast( test.ID, fcst )\n",
    "\n",
    "# Make sure all values that have been 0 for the past 2 observations are predicted to be 0\n",
    "idx = ( 0.1 > Z.iloc[-2:-1,:].sum() )\n",
    "output[idx.index] = 0\n",
    "\n",
    "output.to_csv( 'forecast_7.csv', index=True, header=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (python37)",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
